{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common code and variables for all prediction notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"cmr10\"\n",
    "plt.rcParams[\"font.size\"] = 16\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "from sklearn import linear_model, preprocessing\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, confusion_matrix\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_font_size(fs):\n",
    "    plt.rcParams[\"font.size\"] = fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining MAPE function\n",
    "def MAPE(Y_actual,Y_Predicted):\n",
    "    mape = np.mean(np.abs((Y_actual - Y_Predicted)/Y_actual))*100\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interesting regions to look at\n",
    "# 2000232 = Bney Brak\n",
    "# 2000166 = Tel Aviv\n",
    "# 2000021 = Beit Shemesh (Highest cases in Israel)\n",
    "# 2000241 = Modi'in Elit (Orthodox)\n",
    "# 2000025 = Majdel Shams (Arab)\n",
    "interesting_regions = [231, 165, 20, 240, 24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_to_pickle(file, filename):\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(file, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"Saved file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions, with and without exponential decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 0.5# ** 0.5\n",
    "a = 1\n",
    "n = 15\n",
    "\n",
    "def exponential_weights_daily(r, a, n):\n",
    "    return [a*r**(n-i-1) for i in range(n)]\n",
    "\n",
    "def exponential_weights_weekly(r, a, n):\n",
    "    return np.repeat([a*r**(n-i-1) for i in range(n)], 7)[-n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set exp_decay_weekly or exp_decay_daily to non-zero numbers for that r-value in the above formula\n",
    "\n",
    "def make_osa_preds(X_train, y_train, X_test, y_test, exp_decay_weekly=0, exp_decay_daily=0):\n",
    "    y_preds = list()\n",
    "\n",
    "    history_X = X_train\n",
    "    history_y = y_train\n",
    "    regr = linear_model.LinearRegression()\n",
    "    for i in range(0, len(X_test), 1):\n",
    "        if exp_decay_weekly > 0:\n",
    "            regr.fit(history_X, history_y, sample_weight = exponential_weights_weekly(exp_decay_weekly, 1, len(history_X)))\n",
    "        elif exp_decay_daily > 0:\n",
    "            regr.fit(history_X, history_y, sample_weight = exponential_weights_daily(exp_decay_daily, 1, len(history_X)))\n",
    "        else:\n",
    "            regr.fit(history_X, history_y)\n",
    "        yhat_1 = regr.predict(X_test[i:i+1])   \n",
    "        y_preds.append(yhat_1)\n",
    "        if i>=7:\n",
    "            history_X = np.vstack((history_X, X_test[i-7:i+1-7]))\n",
    "            try:\n",
    "                history_y = np.hstack((history_y, y_test[i-7:i+1-7]))\n",
    "            except:\n",
    "                history_y = np.vstack((history_y, y_test[i-7:i+1-7]))\n",
    "    \n",
    "    return np.maximum(0.0, np.concatenate(y_preds).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set exp_decay_weekly or exp_decay_daily to non-zero numbers for that r-value in the above formula\n",
    "\n",
    "def make_dynamic_preds(X_train, y_train, X_test, y_test, exp_decay_weekly=0, exp_decay_daily=0):\n",
    "    regr = linear_model.LinearRegression()\n",
    "    if exp_decay_weekly > 0:\n",
    "        regr.fit(X_train, y_train.values.ravel(), sample_weight = exponential_weights_weekly(exp_decay_weekly, 1, len(X_train)))\n",
    "    elif exp_decay_daily > 0:\n",
    "        regr.fit(X_train, y_train.values.ravel(), sample_weight = exponential_weights_daily(exp_decay_daily, 1, len(X_train)))\n",
    "    else:\n",
    "        regr.fit(X_train, y_train.values.ravel())\n",
    "    y_pred = regr.predict(X_test)\n",
    "    return np.maximum(0.0, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and testing dates\n",
    "train_begin = \"2020-04-01\"\n",
    "train_end = \"2020-10-09\"\n",
    "test_begin = \"2020-10-16\"\n",
    "\n",
    "new_train_end = \"2020-10-09\"\n",
    "new_test_begin = \"2020-10-16\"\n",
    "test_end_nov = \"2020-11-30\"\n",
    "test_end_dec = \"2020-12-31\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mobility features to use for all prediction tasks\n",
    "\n",
    "press_7 = ['Pressure_7_Adj100k_1dayago']\n",
    "press_7d = ['Diff Pressure_7_Adj100k_1dayago']\n",
    "press_7e = ['Excess Pressure_7_Adj100k_1dayago']\n",
    "#press_8 = ['Pressure_8_Adj100k']\n",
    "#press_8d = ['Diff Pressure_8_Adj100k']\n",
    "#press_8e = ['Excess Pressure_8_Adj100k']\n",
    "#stops = ['Commuter_8', 'Resident_8']\n",
    "im = ['Internal_Movement_7_Adj100k_1dayago']\n",
    "im_d = ['Diff Internal_Movement_7_Adj100k_1dayago']\n",
    "im_e = ['Excess Internal_Movement_7_Adj100k_1dayago']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incidence\n",
    "\n",
    "activecases_1 = ['Active_Cases_7_Adj100k_7_1dayago'] \n",
    "activecases_3 = ['Active_Cases_7_Adj100k_7_1dayago', 'Active_Cases_7_Adj100k_7_2dayago', 'Active_Cases_7_Adj100k_7_3dayago'] \n",
    "activecases_6 = ['Active_Cases_7_Adj100k_7_1dayago', 'Active_Cases_7_Adj100k_7_2dayago', 'Active_Cases_7_Adj100k_7_3dayago',\n",
    "             'Active_Cases_7_Adj100k_7_4dayago', 'Active_Cases_7_Adj100k_7_5dayago', 'Active_Cases_7_Adj100k_7_6dayago']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positivity\n",
    "\n",
    "positivity_lag = ['Positivity_Rate_7_1dayago',\n",
    "'Positivity_Rate_7_2dayago', 'Positivity_Rate_7_3dayago',\n",
    "'Positivity_Rate_7_4dayago', 'Positivity_Rate_7_5dayago',\n",
    "'Positivity_Rate_7_6dayago']\n",
    "positivity_1 = ['Positivity_Rate_7_1dayago']\n",
    "positivity_3 = ['Positivity_Rate_7_1dayago',\n",
    "'Positivity_Rate_7_2dayago', 'Positivity_Rate_7_3dayago']\n",
    "positivity_6 = ['Positivity_Rate_7_1dayago',\n",
    "'Positivity_Rate_7_2dayago', 'Positivity_Rate_7_3dayago',\n",
    "'Positivity_Rate_7_4dayago', 'Positivity_Rate_7_5dayago',\n",
    "'Positivity_Rate_7_6dayago']\n",
    "\n",
    "# Standardized Positivity\n",
    "\n",
    "\n",
    "z_lag = ['z_score_1dayago',\n",
    "'z_score_2dayago', 'z_score_3dayago',\n",
    "'z_score_4dayago', 'z_score_5dayago',\n",
    "'z_score_6dayago']\n",
    "z_1 = ['z_score_1dayago']\n",
    "z_3 = ['z_score_1dayago',\n",
    "'z_score_2dayago', 'z_score_3dayago']\n",
    "z_6 = ['z_score_1dayago',\n",
    "'z_score_2dayago', 'z_score_3dayago',\n",
    "'z_score_4dayago', 'z_score_5dayago',\n",
    "'z_score_6dayago']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Tests\n",
    "\n",
    "newtests_1 = ['New_Tests_7_Adj100k_1dayago'] \n",
    "newtests_3 = ['New_Tests_7_Adj100k_1dayago', 'New_Tests_7_Adj100k_2dayago', 'New_Tests_7_Adj100k_3dayago'] \n",
    "newtests_6 = ['New_Tests_7_Adj100k_1dayago', 'New_Tests_7_Adj100k_2dayago', 'New_Tests_7_Adj100k_3dayago',\n",
    "             'New_Tests_7_Adj100k_4dayago', 'New_Tests_7_Adj100k_5dayago', 'New_Tests_7_Adj100k_6dayago']\n",
    "\n",
    "newtests_lag = ['New_Tests_7_Adj100k_1dayago', 'New_Tests_7_Adj100k_2dayago',\n",
    "'New_Tests_7_Adj100k_3dayago', 'New_Tests_7_Adj100k_4dayago', 'New_Tests_7_Adj100k_5dayago',\n",
    "'New_Tests_7_Adj100k_6dayago']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Cases\n",
    "\n",
    "newcases_1 = ['New_Cases_7_Adj100k_1dayago']\n",
    "newcases_3 = ['New_Cases_7_Adj100k_1dayago', 'New_Cases_7_Adj100k_2dayago', 'New_Cases_7_Adj100k_3dayago']\n",
    "newcases_6 = ['New_Cases_7_Adj100k_1dayago', 'New_Cases_7_Adj100k_2dayago', 'New_Cases_7_Adj100k_3dayago',\n",
    "'New_Cases_7_Adj100k_4dayago', 'New_Cases_7_Adj100k_5dayago', 'New_Cases_7_Adj100k_6dayago']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "positivity_label = 'Positivity_Rate_7_next7days'\n",
    "\n",
    "\n",
    "pos_feature_sets = dict()\n",
    "pos_feature_sets[1] = positivity_6 + press_7\n",
    "pos_feature_sets[2] = positivity_6 + press_7d\n",
    "pos_feature_sets[3] = positivity_6 + press_7e\n",
    "pos_feature_sets[4] = positivity_6\n",
    "pos_feature_sets[5] = positivity_3 + press_7\n",
    "pos_feature_sets[6] = positivity_3 + press_7d\n",
    "pos_feature_sets[7] = positivity_3 + press_7e\n",
    "pos_feature_sets[8] = positivity_3\n",
    "pos_feature_sets[9] = positivity_1 + press_7\n",
    "pos_feature_sets[10] = positivity_1 + press_7d\n",
    "pos_feature_sets[11] = positivity_1 + press_7e\n",
    "pos_feature_sets[12] = positivity_1\n",
    "pos_feature_sets[13] = positivity_1 + press_7 + im\n",
    "pos_feature_sets[14] = positivity_1 + press_7d + im_d\n",
    "pos_feature_sets[15] = positivity_1 + press_7e + im_e\n",
    "pos_feature_sets[16] =  positivity_1 + im_d\n",
    "pos_feature_sets[17] =  positivity_1 + im_e\n",
    "pos_feature_sets[18] =  positivity_1 + im_d + newtests_1\n",
    "pos_feature_sets[19] =  positivity_1 + im_e + newtests_1\n",
    "pos_feature_sets[20] = positivity_1 + press_7 + newtests_1\n",
    "pos_feature_sets[21] = positivity_1 + press_7d + newtests_1\n",
    "pos_feature_sets[22] = positivity_1 + press_7e + newtests_1\n",
    "pos_feature_sets[23] = press_7 + im + newtests_1\n",
    "pos_feature_sets[24] = press_7 + im\n",
    "pos_feature_sets[25] =  positivity_1 + im_d + newcases_1\n",
    "pos_feature_sets[26] =  positivity_1 + im_e + newcases_1\n",
    "pos_feature_sets[27] = positivity_1 + press_7 + newcases_1\n",
    "pos_feature_sets[28] = positivity_1 + press_7d + newcases_1\n",
    "pos_feature_sets[29] = positivity_1 + press_7e + newcases_1\n",
    "pos_feature_sets[30] = press_7 + im + newcases_1\n",
    "pos_feature_sets[31] =  positivity_3 + im_d\n",
    "pos_feature_sets[32] =  positivity_3 + im_e\n",
    "pos_feature_sets[33] =  positivity_3 + im_d + newtests_1\n",
    "pos_feature_sets[34] =  positivity_3 + im_e + newtests_1\n",
    "pos_feature_sets[35] = positivity_3 + press_7 + newtests_1\n",
    "pos_feature_sets[36] = positivity_3 + press_7d + newtests_1\n",
    "pos_feature_sets[37] = positivity_3 + press_7e + newtests_1\n",
    "pos_feature_sets[38] =  positivity_3 + im_d + newcases_1\n",
    "pos_feature_sets[39] =  positivity_3 + im_e + newcases_1\n",
    "pos_feature_sets[40] = positivity_3 + press_7 + newcases_1\n",
    "pos_feature_sets[41] = positivity_3 + press_7d + newcases_1\n",
    "pos_feature_sets[42] = positivity_3 + press_7e + newcases_1\n",
    "pos_feature_sets[43] =  positivity_6 + im_d\n",
    "pos_feature_sets[44] =  positivity_6 + im_e\n",
    "pos_feature_sets[45] =  positivity_6 + im_d + newtests_1\n",
    "pos_feature_sets[46] =  positivity_6 + im_e + newtests_1\n",
    "pos_feature_sets[47] = positivity_6 + press_7 + newtests_1\n",
    "pos_feature_sets[48] = positivity_6 + press_7d + newtests_1\n",
    "pos_feature_sets[49] = positivity_6 + press_7e + newtests_1\n",
    "pos_feature_sets[50] =  positivity_6 + im_d + newcases_1\n",
    "pos_feature_sets[51] =  positivity_6 + im_e + newcases_1\n",
    "pos_feature_sets[52] = positivity_6 + press_7 + newcases_1\n",
    "pos_feature_sets[53] = positivity_6 + press_7d + newcases_1\n",
    "pos_feature_sets[54] = positivity_6 + press_7e + newcases_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_label = 'z_score'\n",
    "\n",
    "\n",
    "z_feature_sets = dict()\n",
    "z_feature_sets[1] = z_6 + press_7\n",
    "z_feature_sets[2] = z_6 + press_7d\n",
    "z_feature_sets[3] = z_6 + press_7e\n",
    "z_feature_sets[4] = z_6\n",
    "z_feature_sets[5] = z_3 + press_7\n",
    "z_feature_sets[6] = z_3 + press_7d\n",
    "z_feature_sets[7] = z_3 + press_7e\n",
    "z_feature_sets[8] = z_3\n",
    "z_feature_sets[9] = z_1 + press_7\n",
    "z_feature_sets[10] = z_1 + press_7d\n",
    "z_feature_sets[11] = z_1 + press_7e\n",
    "z_feature_sets[12] = z_1\n",
    "z_feature_sets[13] = z_1 + press_7 + im\n",
    "z_feature_sets[14] = z_1 + press_7d + im_d\n",
    "z_feature_sets[15] = z_1 + press_7e + im_e\n",
    "z_feature_sets[16] =  z_1 + im_d\n",
    "z_feature_sets[17] =  z_1 + im_e\n",
    "z_feature_sets[18] =  z_1 + im_d + newtests_1\n",
    "z_feature_sets[19] =  z_1 + im_e + newtests_1\n",
    "z_feature_sets[20] = z_1 + press_7 + newtests_1\n",
    "z_feature_sets[21] = z_1 + press_7d + newtests_1\n",
    "z_feature_sets[22] = z_1 + press_7e + newtests_1\n",
    "z_feature_sets[23] = press_7 + im + newtests_1\n",
    "z_feature_sets[24] = press_7 + im\n",
    "z_feature_sets[25] =  z_1 + im_d + newcases_1\n",
    "z_feature_sets[26] =  z_1 + im_e + newcases_1\n",
    "z_feature_sets[27] = z_1 + press_7 + newcases_1\n",
    "z_feature_sets[28] = z_1 + press_7d + newcases_1\n",
    "z_feature_sets[29] = z_1 + press_7e + newcases_1\n",
    "z_feature_sets[30] = press_7 + im + newcases_1\n",
    "z_feature_sets[31] =  z_3 + im_d\n",
    "z_feature_sets[32] =  z_3 + im_e\n",
    "z_feature_sets[33] =  z_3 + im_d + newtests_1\n",
    "z_feature_sets[34] =  z_3 + im_e + newtests_1\n",
    "z_feature_sets[35] = z_3 + press_7 + newtests_1\n",
    "z_feature_sets[36] = z_3 + press_7d + newtests_1\n",
    "z_feature_sets[37] = z_3 + press_7e + newtests_1\n",
    "z_feature_sets[38] =  z_3 + im_d + newcases_1\n",
    "z_feature_sets[39] =  z_3 + im_e + newcases_1\n",
    "z_feature_sets[40] = z_3 + press_7 + newcases_1\n",
    "z_feature_sets[41] = z_3 + press_7d + newcases_1\n",
    "z_feature_sets[42] = z_3 + press_7e + newcases_1\n",
    "z_feature_sets[43] =  z_6 + im_d\n",
    "z_feature_sets[44] =  z_6 + im_e\n",
    "z_feature_sets[45] =  z_6 + im_d + newtests_1\n",
    "z_feature_sets[46] =  z_6 + im_e + newtests_1\n",
    "z_feature_sets[47] = z_6 + press_7 + newtests_1\n",
    "z_feature_sets[48] = z_6 + press_7d + newtests_1\n",
    "z_feature_sets[49] = z_6 + press_7e + newtests_1\n",
    "z_feature_sets[50] =  z_6 + im_d + newcases_1\n",
    "z_feature_sets[51] =  z_6 + im_e + newcases_1\n",
    "z_feature_sets[52] = z_6 + press_7 + newcases_1\n",
    "z_feature_sets[53] = z_6 + press_7d + newcases_1\n",
    "z_feature_sets[54] = z_6 + press_7e + newcases_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "activecases_label = \"Active_Cases_7_Adj100k_next7days\"\n",
    "\n",
    "activecases_feature_sets = dict()\n",
    "activecases_feature_sets[1] = activecases_6 + press_7\n",
    "activecases_feature_sets[2] = activecases_6 + press_7d\n",
    "activecases_feature_sets[3] = activecases_6 + press_7e\n",
    "activecases_feature_sets[4] = activecases_6\n",
    "activecases_feature_sets[5] = activecases_3 + press_7\n",
    "activecases_feature_sets[6] = activecases_3 + press_7d\n",
    "activecases_feature_sets[7] = activecases_3 + press_7e\n",
    "activecases_feature_sets[8] = activecases_3\n",
    "activecases_feature_sets[9] = activecases_1 + press_7\n",
    "activecases_feature_sets[10] = activecases_1 + press_7d\n",
    "activecases_feature_sets[11] = activecases_1 + press_7e\n",
    "activecases_feature_sets[12] = activecases_1\n",
    "activecases_feature_sets[13] = activecases_1 + press_7 + im\n",
    "activecases_feature_sets[14] = activecases_1 + press_7d + im_d\n",
    "activecases_feature_sets[15] = activecases_1 + press_7e + im_e\n",
    "activecases_feature_sets[16] = activecases_1 + im\n",
    "activecases_feature_sets[17] = activecases_6 + im_d\n",
    "activecases_feature_sets[18] = activecases_6 + im_e\n",
    "activecases_feature_sets[19] = activecases_6 + im\n",
    "activecases_feature_sets[20] = activecases_6 + press_7 + im\n",
    "activecases_feature_sets[21] = activecases_6 + press_7d + im_d\n",
    "activecases_feature_sets[22] = activecases_6 + press_7e + im_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtests_label = 'NewTests_7_Adj100k_next7days'\n",
    "\n",
    "newtests_feature_sets = dict()\n",
    "newtests_feature_sets[1] = newtests_6 + press_7\n",
    "newtests_feature_sets[2] = newtests_6 + press_7d\n",
    "newtests_feature_sets[3] = newtests_6 + press_7e\n",
    "newtests_feature_sets[4] = newtests_6\n",
    "newtests_feature_sets[5] = newtests_3 + press_7\n",
    "newtests_feature_sets[6] = newtests_3 + press_7d\n",
    "newtests_feature_sets[7] = newtests_3 + press_7e\n",
    "newtests_feature_sets[8] = newtests_3\n",
    "newtests_feature_sets[9] = newtests_1 + press_7\n",
    "newtests_feature_sets[10] = newtests_1 + press_7d\n",
    "newtests_feature_sets[11] = newtests_1 + press_7e\n",
    "newtests_feature_sets[12] = newtests_1\n",
    "newtests_feature_sets[13] = newtests_1 + press_7 + im\n",
    "newtests_feature_sets[14] = newtests_1 + press_7d + im_d\n",
    "newtests_feature_sets[15] = newtests_1 + press_7e + im_e\n",
    "newtests_feature_sets[16] = newtests_1 + im\n",
    "newtests_feature_sets[17] = newtests_1 + im_d\n",
    "newtests_feature_sets[18] = newtests_1 + im_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "newcases_label = \"NewCases_7_Adj100k_next7days\"\n",
    "\n",
    "newcases_feature_sets = dict()\n",
    "newcases_feature_sets[1] = newcases_6 + press_7\n",
    "newcases_feature_sets[2] = newcases_6 + press_7d\n",
    "newcases_feature_sets[3] = newcases_6 + press_7e\n",
    "newcases_feature_sets[4] = newcases_6\n",
    "newcases_feature_sets[5] = newcases_3 + press_7\n",
    "newcases_feature_sets[6] = newcases_3 + press_7d\n",
    "newcases_feature_sets[7] = newcases_3 + press_7e\n",
    "newcases_feature_sets[8] = newcases_3\n",
    "newcases_feature_sets[9] = newcases_1 + press_7\n",
    "newcases_feature_sets[10] = newcases_1 + press_7d\n",
    "newcases_feature_sets[11] = newcases_1 + press_7e\n",
    "newcases_feature_sets[12] = newcases_1\n",
    "newcases_feature_sets[13] = newcases_1 + press_7 + im\n",
    "newcases_feature_sets[14] = newcases_1 + press_7d + im_d\n",
    "newcases_feature_sets[15] = newcases_1 + press_7e + im_e\n",
    "newcases_feature_sets[16] =  newcases_1 + im_d\n",
    "newcases_feature_sets[17] =  newcases_1 + im_e\n",
    "newcases_feature_sets[18] =  newcases_1 + im_d + newtests_1\n",
    "newcases_feature_sets[19] =  newcases_1 + im_e + newtests_1\n",
    "newcases_feature_sets[20] = newcases_1 + press_7 + newtests_1\n",
    "newcases_feature_sets[21] = newcases_1 + press_7d + newtests_1\n",
    "newcases_feature_sets[22] = newcases_1 + press_7e + newtests_1\n",
    "newcases_feature_sets[23] = press_7 + im + newtests_1\n",
    "newcases_feature_sets[24] = press_7 + im\n",
    "newcases_feature_sets[25] =  newcases_1 + im_d + positivity_1\n",
    "newcases_feature_sets[26] =  newcases_1 + im_e + positivity_1\n",
    "newcases_feature_sets[27] = newcases_1 + press_7 + positivity_1\n",
    "newcases_feature_sets[28] = newcases_1 + press_7d + positivity_1\n",
    "newcases_feature_sets[29] = newcases_1 + press_7e + positivity_1\n",
    "newcases_feature_sets[30] = press_7 + im + positivity_1\n",
    "newcases_feature_sets[31] =  newcases_3 + im_d\n",
    "newcases_feature_sets[32] =  newcases_3 + im_e\n",
    "newcases_feature_sets[33] =  newcases_3 + im_d + newtests_1\n",
    "newcases_feature_sets[34] =  newcases_3 + im_e + newtests_1\n",
    "newcases_feature_sets[35] = newcases_3 + press_7 + newtests_1\n",
    "newcases_feature_sets[36] = newcases_3 + press_7d + newtests_1\n",
    "newcases_feature_sets[37] = newcases_3 + press_7e + newtests_1\n",
    "newcases_feature_sets[38] =  newcases_3 + im_d + positivity_1\n",
    "newcases_feature_sets[39] =  newcases_3 + im_e + positivity_1\n",
    "newcases_feature_sets[40] = newcases_3 + press_7 + positivity_1\n",
    "newcases_feature_sets[41] = newcases_3 + press_7d + positivity_1\n",
    "newcases_feature_sets[42] = newcases_3 + press_7e + positivity_1\n",
    "newcases_feature_sets[43] =  newcases_6 + im_d\n",
    "newcases_feature_sets[44] =  newcases_6 + im_e\n",
    "newcases_feature_sets[45] =  newcases_6 + im_d + newtests_1\n",
    "newcases_feature_sets[46] =  newcases_6 + im_e + newtests_1\n",
    "newcases_feature_sets[47] = newcases_6 + press_7 + newtests_1\n",
    "newcases_feature_sets[48] = newcases_6 + press_7d + newtests_1\n",
    "newcases_feature_sets[49] = newcases_6 + press_7e + newtests_1\n",
    "newcases_feature_sets[50] =  newcases_6 + im_d + positivity_1\n",
    "newcases_feature_sets[51] =  newcases_6 + im_e + positivity_1\n",
    "newcases_feature_sets[52] = newcases_6 + press_7 + positivity_1\n",
    "newcases_feature_sets[53] = newcases_6 + press_7d + positivity_1\n",
    "newcases_feature_sets[54] = newcases_6 + press_7e + positivity_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Trend and Magnitude Accuracy for New Cases and Positivity Rate Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define trend accuracy\n",
    "def trend_accuracy(pred, actual):\n",
    "    alpha_hat = pd.Series(pred).diff().fillna(0.001)\n",
    "    alpha = pd.Series(actual).diff().fillna(0.001).replace(0,0.001)\n",
    "    c = pd.Series(np.sign(np.array(alpha_hat)/np.array(alpha))).clip(lower=0)\n",
    "    evaluate = c[:-7] # Remove the last 7 days, for which we don't have data\n",
    "    return sum(evaluate)/len(evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "widespread = 7.0\n",
    "substantial = 4.0\n",
    "moderate = 1.0\n",
    "minimal = 0.0\n",
    "\n",
    "def classify_magnitude_newcases(new_cases_per_100k):\n",
    "    if new_cases_per_100k >= widespread:\n",
    "        return 4\n",
    "    if new_cases_per_100k >= substantial:\n",
    "        return 3\n",
    "    if new_cases_per_100k >= moderate:\n",
    "        return 2\n",
    "    return 1\n",
    "\n",
    "# Define MA, MA within 1 tier, and CM for pos rate\n",
    "\n",
    "def confusion_matrix_nc(pred, actual):\n",
    "    return cm_4tier_h(pred, actual, classify_magnitude_newcases)\n",
    "\n",
    "def magnitude_accuracy_nc(pred, actual):\n",
    "    return ma_h(pred, actual, confusion_matrix_nc)\n",
    "\n",
    "def magnitude_accuracy_1_nc(pred, actual):\n",
    "    return ma_1tier_h(pred, actual, confusion_matrix_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_2(pred, actual):\n",
    "    mag_hat = pd.Series(pred).fillna(0.001).apply(classify_magnitude)[:-7]\n",
    "    mag = pd.Series(actual).fillna(0.001).apply(classify_magnitude)[:-7]\n",
    "    return confusion_matrix(mag, mag_hat, labels=[1, 2, 3, 4])\n",
    "\n",
    "def normalize_cm(cm):\n",
    "    return cm / cm.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_cm(cm):\n",
    "    return cm / cm.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "widespread_positivity = 0.08\n",
    "substantial_positivity = 0.05\n",
    "moderate_positivity = 0.02\n",
    "minimal_positivity = 0.0\n",
    "\n",
    "def classify_magnitude_positivity(positivity_rate):\n",
    "    if positivity_rate >= widespread_positivity:\n",
    "        return 4\n",
    "    if positivity_rate >= substantial_positivity:\n",
    "        return 3\n",
    "    if positivity_rate >= moderate_positivity:\n",
    "        return 2\n",
    "    return 1\n",
    "\n",
    "\n",
    "# Define MA, MA within 1 tier, and CM for pos rate\n",
    "\n",
    "def confusion_matrix_pr(pred, actual):\n",
    "    return cm_4tier_h(pred, actual, classify_magnitude_positivity)\n",
    "\n",
    "def magnitude_accuracy_pr(pred, actual):\n",
    "    return ma_h(pred, actual, confusion_matrix_pr)\n",
    "\n",
    "def magnitude_accuracy_1_pr(pred, actual):\n",
    "    return ma_1tier_h(pred, actual, confusion_matrix_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_magnitude_overall(new_cases_per_100k, positivity_rate):\n",
    "    if new_cases_per_100k >= widespread or positivity_rate >= widespread_positivity:\n",
    "        return 4\n",
    "    if new_cases_per_100k >= substantial or positivity_rate >= substantial_positivity:\n",
    "        return 3\n",
    "    if new_cases_per_100k >= moderate or positivity_rate >= moderate_positivity:\n",
    "        return 2\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define magnitude accuracy\n",
    "def ma_h(pred, actual, cm_handle):\n",
    "    cm = cm_handle(pred, actual)\n",
    "    return np.trace(cm) / np.sum(cm, axis=None)\n",
    "\n",
    "# Define magnitude accuracy within 1 tier\n",
    "def ma_1tier_h(pred, actual, cm_handle):\n",
    "    cm = cm_handle(pred, actual)\n",
    "    return (sum(np.diag(cm, k=1)) + sum(np.diag(cm, k=0)) + sum(np.diag(cm, k=-1))) / np.sum(cm, axis=None)\n",
    "\n",
    "# Define magnitude accuracy directly from CM\n",
    "def ma_from_cm(cm):\n",
    "    return np.trace(cm) / np.sum(cm, axis=None)\n",
    "\n",
    "# Define magnitude accuracy within 1 tier directly from CM\n",
    "def ma_1tier_from_cm(cm):\n",
    "    return (sum(np.diag(cm, k=1)) + sum(np.diag(cm, k=0)) + sum(np.diag(cm, k=-1))) / np.sum(cm, axis=None)\n",
    "\n",
    "\n",
    "# Define confusion matrix for 5 tiers\n",
    "def cm_5tier_h(pred, actual, classify_handle):\n",
    "    mag_hat = pd.Series(pred).fillna(0.001).apply(classify_handle)[:-7]\n",
    "    mag = pd.Series(actual).fillna(0.001).apply(classify_handle)[:-7]\n",
    "    return confusion_matrix(mag, mag_hat, labels=[0, 1, 2, 3, 4])\n",
    "\n",
    "# Define confusion matrix for 4 tiers\n",
    "def cm_4tier_h(pred, actual, classify_handle):\n",
    "    mag_hat = pd.Series(pred).fillna(0.001).apply(classify_handle)[:-7]\n",
    "    mag = pd.Series(actual).fillna(0.001).apply(classify_handle)[:-7]\n",
    "    return confusion_matrix(mag, mag_hat, labels=[1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_ac = 455\n",
    "t4_ac = 210\n",
    "t3_ac = 115\n",
    "t2_ac = 45\n",
    "\n",
    "def classify_magnitude_ac(active_cases):\n",
    "    if active_cases >= t5_ac:\n",
    "        return 4\n",
    "    if active_cases >= t4_ac:\n",
    "        return 3\n",
    "    if active_cases >= t3_ac:\n",
    "        return 2\n",
    "    if active_cases >= t2_ac:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# Define MA, MA within 1 tier, and CM for active cases\n",
    "def confusion_matrix_ac(pred, actual):\n",
    "    return cm_5tier_h(pred, actual, classify_magnitude_ac)\n",
    "\n",
    "def magnitude_accuracy_ac(pred, actual):\n",
    "    return ma_h(pred, actual, confusion_matrix_ac)\n",
    "\n",
    "def magnitude_accuracy_1_ac(pred, actual):\n",
    "    return ma_1tier_h(pred, actual, confusion_matrix_ac)\n",
    "\n",
    "# new cases tiering system for MA\n",
    "\n",
    "t5_nct = 33\n",
    "t4_nct = 16\n",
    "t3_nct = 9\n",
    "t2_nct = 3\n",
    "#t5_nct = 34\n",
    "#t4_nct = 15\n",
    "#t3_nct = 8\n",
    "#t2_nct = 2\n",
    "\n",
    "def classify_magnitude_nct(new_cases):\n",
    "    if new_cases >= t5_nct:\n",
    "        return 4\n",
    "    if new_cases >= t4_nct:\n",
    "        return 3\n",
    "    if new_cases >= t3_nct:\n",
    "        return 2\n",
    "    if new_cases >= t2_nct:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "# Define MA, MA within 1 tier, and CM for active cases\n",
    "\n",
    "def confusion_matrix_nct(pred, actual):\n",
    "    return cm_5tier_h(pred, actual, classify_magnitude_nct)\n",
    "\n",
    "def magnitude_accuracy_nct(pred, actual):\n",
    "    return ma_h(pred, actual, confusion_matrix_nct)\n",
    "\n",
    "def magnitude_accuracy_1_nct(pred, actual):\n",
    "    return ma_1tier_h(pred, actual, confusion_matrix_nct)\n",
    "\n",
    "# pos rate tiering system\n",
    "\n",
    "t5_prt = 0.10\n",
    "t4_prt = 0.07\n",
    "t3_prt = 0.05\n",
    "t2_prt = 0.025\n",
    "\n",
    "def classify_magnitude_prt(pos_rate):\n",
    "    if pos_rate >= t5_prt:\n",
    "        return 4\n",
    "    if pos_rate >= t4_prt:\n",
    "        return 3\n",
    "    if pos_rate >= t3_prt:\n",
    "        return 2\n",
    "    if pos_rate >= t2_prt:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "# Define MA, MA within 1 tier, and CM for pos rate\n",
    "\n",
    "def confusion_matrix_prt(pred, actual):\n",
    "    return cm_5tier_h(pred, actual, classify_magnitude_prt)\n",
    "\n",
    "def magnitude_accuracy_prt(pred, actual):\n",
    "    return ma_h(pred, actual, confusion_matrix_prt)\n",
    "\n",
    "def magnitude_accuracy_1_prt(pred, actual):\n",
    "    return ma_1tier_h(pred, actual, confusion_matrix_prt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "widespread_dt = 1.5\n",
    "substantial_dt = 4\n",
    "moderate_dt = 52\n",
    "\n",
    "def classify_magnitude_dt(doubling_time):\n",
    "    if doubling_time <= widespread_dt:\n",
    "        return 4\n",
    "    if doubling_time <= substantial_dt:\n",
    "        return 3\n",
    "    if doubling_time <= moderate_dt:\n",
    "        return 2\n",
    "    return 1\n",
    "\n",
    "\n",
    "# Define magnitude accuracy for positivity rate\n",
    "def magnitude_accuracy_dt(pred, actual):\n",
    "    mag_hat = pd.Series(pred).fillna(0.001).apply(classify_magnitude_dt)\n",
    "    mag = pd.Series(actual).fillna(0.001).apply(classify_magnitude_dt)\n",
    "    mag_diff = np.array(mag_hat) - np.array(mag)\n",
    "    evaluate = mag_diff[:-7] # Remove the last 7 days, for which we don't have data\n",
    "    eval_len = len(evaluate)\n",
    "    return (eval_len - np.count_nonzero(evaluate))/eval_len\n",
    "\n",
    "def confusion_matrix_dt(pred, actual):\n",
    "    mag_hat = pd.Series(pred).fillna(0.001).apply(classify_magnitude_dt)[:-7]\n",
    "    mag = pd.Series(actual).fillna(0.001).apply(classify_magnitude_dt)[:-7]\n",
    "    return confusion_matrix(mag, mag_hat, labels=[1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
